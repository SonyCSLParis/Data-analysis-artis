{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff3429d",
   "metadata": {},
   "source": [
    "# Seconda Elementare Dataset Analysis üìä\n",
    "\n",
    "This notebook provides a comprehensive analysis of the `seconda-elementare-with-answer.json` dataset to identify missing data and ensure data quality.\n",
    "\n",
    "## Objectives:\n",
    "- Load and explore the dataset structure\n",
    "- Identify missing data patterns\n",
    "- Analyze data completeness\n",
    "- Generate data quality report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c82378",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "592536e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6c46a",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25ff1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading dataset from: json-with-correct-answers/quinta-elementare_with_answers.json\n",
      "‚úÖ Dataset loaded successfully!\n",
      "üìä File size: 64.4 KB\n",
      "\n",
      "üîç DATA STRUCTURE:\n",
      "Type: <class 'dict'>\n",
      "Keys: ['dataset_name', 'language', 'stories']\n"
     ]
    }
   ],
   "source": [
    "# Define file path\n",
    "file_path = Path(\"json-with-correct-answers/quinta-elementare_with_answers.json\")\n",
    "\n",
    "# Check if file exists\n",
    "if not file_path.exists():\n",
    "    # Try alternative locations\n",
    "    alternative_paths = [\n",
    "        Path(\"quinta-elementare_with_answers.json\"),\n",
    "        Path(\"json-with-correct-answers/quinta-elementare_with_answers.json\"),\n",
    "        Path(\"results-texts/quinta-elementare_with_answers.json\")\n",
    "    ]\n",
    "    \n",
    "    for alt_path in alternative_paths:\n",
    "        if alt_path.exists():\n",
    "            file_path = alt_path\n",
    "            break\n",
    "    else:\n",
    "        print(\"‚ùå File not found. Available files:\")\n",
    "        for f in Path(\".\").glob(\"**/*.json\"):\n",
    "            print(f\"  - {f}\")\n",
    "        raise FileNotFoundError(\"Dataset file not found\")\n",
    "\n",
    "print(f\"üìÅ Loading dataset from: {file_path}\")\n",
    "\n",
    "# Load JSON data\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìä File size: {file_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Print the structure to understand the format\n",
    "    print(\"\\nüîç DATA STRUCTURE:\")\n",
    "    print(f\"Type: {type(data)}\")\n",
    "    if isinstance(data, dict):\n",
    "        print(f\"Keys: {list(data.keys())}\")\n",
    "    elif isinstance(data, list):\n",
    "        print(f\"Length: {len(data)}\")\n",
    "        if data:\n",
    "            print(f\"First item keys: {list(data[0].keys()) if isinstance(data[0], dict) else type(data[0])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebdbc6",
   "metadata": {},
   "source": [
    "## 3. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4abfd15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DATASET STRUCTURE OVERVIEW\n",
      "==================================================\n",
      "üìö Dataset Name: letture_quinta_it_mcq\n",
      "üåç Language: it\n",
      "üìñ Total Stories: 17\n",
      "ü§ñ Enhanced with AI: No\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìã STORIES SUMMARY:\n",
      " 1. tre volte bau\n",
      "    Questions: 10\n",
      "    Has passage: Yes\n",
      "    Has source: No\n",
      " 2. il gatto osiride\n",
      "    Questions: 10\n",
      "    Has passage: Yes\n",
      "    Has source: No\n",
      " 3. verso i mari del sud\n",
      "    Questions: 10\n",
      "    Has passage: Yes\n",
      "    Has source: No\n",
      " 4. mi piaci, sai\n",
      "    Questions: 10\n",
      "    Has passage: Yes\n",
      "    Has source: No\n",
      " 5. la testimone oculare\n",
      "    Questions: 10\n",
      "    Has passage: Yes\n",
      "    Has source: No\n",
      "    ...\n",
      "17. l‚Äôultima estate, berlino 1961\n",
      "    Questions: 10\n",
      "\n",
      "üî¢ TOTAL QUESTIONS: 170\n",
      "‚úÖ Questions with correct answers: 170\n",
      "‚ùå Questions missing answers: 0\n",
      "üìä Completion rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset structure\n",
    "print(\"üîç DATASET STRUCTURE OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic information\n",
    "print(f\"üìö Dataset Name: {data.get('dataset_name', 'Not specified')}\")\n",
    "print(f\"üåç Language: {data.get('language', 'Not specified')}\")\n",
    "print(f\"üìñ Total Stories: {len(data.get('stories', []))}\")\n",
    "\n",
    "# Check if enhanced with AI\n",
    "if data.get('enhanced_with_ai'):\n",
    "    print(f\"ü§ñ Enhanced with AI: Yes (Model: {data.get('ai_model', 'Unknown')})\")\n",
    "    print(f\"‚è∞ Enhancement Date: {data.get('enhancement_timestamp', 'Unknown')}\")\n",
    "else:\n",
    "    print(\"ü§ñ Enhanced with AI: No\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# Stories overview\n",
    "stories = data.get('stories', [])\n",
    "if stories:\n",
    "    print(f\"\\nüìã STORIES SUMMARY:\")\n",
    "    for i, story in enumerate(stories[:5], 1):\n",
    "        print(f\"{i:2d}. {story.get('title', 'No title')[:50]}\")\n",
    "        print(f\"    Questions: {len(story.get('questions', []))}\")\n",
    "        print(f\"    Has passage: {'Yes' if story.get('passage') else 'No'}\")\n",
    "        print(f\"    Has source: {'Yes' if story.get('source') else 'No'}\")\n",
    "    \n",
    "    if len(stories) > 5:\n",
    "        print(\"    ...\")\n",
    "        last_story = stories[-1]\n",
    "        print(f\"{len(stories):2d}. {last_story.get('title', 'No title')[:50]}\")\n",
    "        print(f\"    Questions: {len(last_story.get('questions', []))}\")\n",
    "\n",
    "# Total questions\n",
    "total_questions = sum(len(story.get('questions', [])) for story in stories)\n",
    "print(f\"\\nüî¢ TOTAL QUESTIONS: {total_questions}\")\n",
    "\n",
    "# Questions with answers\n",
    "questions_with_answers = 0\n",
    "for story in stories:\n",
    "    for q in story.get('questions', []):\n",
    "        if 'correct_answer' in q:\n",
    "            questions_with_answers += 1\n",
    "\n",
    "print(f\"‚úÖ Questions with correct answers: {questions_with_answers}\")\n",
    "print(f\"‚ùå Questions missing answers: {total_questions - questions_with_answers}\")\n",
    "\n",
    "completion_rate = (questions_with_answers / total_questions * 100) if total_questions > 0 else 0\n",
    "print(f\"üìä Completion rate: {completion_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676e6c0",
   "metadata": {},
   "source": [
    "## 4. Check for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c94c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç MISSING DATA ANALYSIS\n",
      "==================================================\n",
      "üìä MISSING DATA SUMMARY:\n",
      "Stories missing title: 0\n",
      "Stories missing passage: 0\n",
      "Stories missing source: 17\n",
      "Stories missing questions: 0\n",
      "Questions missing text: 0\n",
      "Questions missing options: 0\n",
      "Questions with incomplete options: 0\n",
      "Questions missing correct answer: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive missing data analysis\n",
    "missing_data_report = {\n",
    "    'stories_missing_title': [],\n",
    "    'stories_missing_passage': [],\n",
    "    'stories_missing_source': [],\n",
    "    'stories_missing_questions': [],\n",
    "    'questions_missing_text': [],\n",
    "    'questions_missing_options': [],\n",
    "    'questions_missing_correct_answer': [],\n",
    "    'questions_incomplete_options': []\n",
    "}\n",
    "\n",
    "print(\"üîç MISSING DATA ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze each story\n",
    "for story_idx, story in enumerate(stories):\n",
    "    story_title = story.get('title', f'Story {story_idx + 1}')\n",
    "    \n",
    "    # Check story-level missing data\n",
    "    if not story.get('title'):\n",
    "        missing_data_report['stories_missing_title'].append(story_idx + 1)\n",
    "    \n",
    "    if not story.get('passage'):\n",
    "        missing_data_report['stories_missing_passage'].append((story_idx + 1, story_title))\n",
    "    \n",
    "    if not story.get('source'):\n",
    "        missing_data_report['stories_missing_source'].append((story_idx + 1, story_title))\n",
    "    \n",
    "    questions = story.get('questions', [])\n",
    "    if not questions:\n",
    "        missing_data_report['stories_missing_questions'].append((story_idx + 1, story_title))\n",
    "    \n",
    "    # Check question-level missing data\n",
    "    for q_idx, question in enumerate(questions):\n",
    "        q_id = f\"Story {story_idx + 1}, Q{q_idx + 1}\"\n",
    "        \n",
    "        if not question.get('question'):\n",
    "            missing_data_report['questions_missing_text'].append(q_id)\n",
    "        \n",
    "        options = question.get('options', [])\n",
    "        if not options:\n",
    "            missing_data_report['questions_missing_options'].append(q_id)\n",
    "        elif len(options) != 3:\n",
    "            missing_data_report['questions_incomplete_options'].append((q_id, len(options)))\n",
    "        \n",
    "        if 'correct_answer' not in question:\n",
    "            missing_data_report['questions_missing_correct_answer'].append(q_id)\n",
    "\n",
    "# Print missing data summary\n",
    "print(\"üìä MISSING DATA SUMMARY:\")\n",
    "print(f\"Stories missing title: {len(missing_data_report['stories_missing_title'])}\")\n",
    "print(f\"Stories missing passage: {len(missing_data_report['stories_missing_passage'])}\")\n",
    "print(f\"Stories missing source: {len(missing_data_report['stories_missing_source'])}\")\n",
    "print(f\"Stories missing questions: {len(missing_data_report['stories_missing_questions'])}\")\n",
    "print(f\"Questions missing text: {len(missing_data_report['questions_missing_text'])}\")\n",
    "print(f\"Questions missing options: {len(missing_data_report['questions_missing_options'])}\")\n",
    "print(f\"Questions with incomplete options: {len(missing_data_report['questions_incomplete_options'])}\")\n",
    "print(f\"Questions missing correct answer: {len(missing_data_report['questions_missing_correct_answer'])}\")\n",
    "\n",
    "# Show details for significant issues\n",
    "if missing_data_report['stories_missing_passage']:\n",
    "    print(f\"\\n‚ö†Ô∏è  Stories missing passage:\")\n",
    "    for story_num, title in missing_data_report['stories_missing_passage']:\n",
    "        print(f\"   Story {story_num}: {title}\")\n",
    "\n",
    "if missing_data_report['questions_missing_correct_answer']:\n",
    "    print(f\"\\n‚ö†Ô∏è  Questions missing correct answer (showing first 10):\")\n",
    "    for q_id in missing_data_report['questions_missing_correct_answer'][:10]:\n",
    "        print(f\"   {q_id}\")\n",
    "    if len(missing_data_report['questions_missing_correct_answer']) > 10:\n",
    "        print(f\"   ... and {len(missing_data_report['questions_missing_correct_answer']) - 10} more\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
